# **Chap7 Clustering**

主要是聚类的两种方法发**,K-均值聚类方法,模糊k-均值聚类,谱聚类**,高斯混合聚类,无限高斯混合

**<font color=red>是一种非监督学习的方法</font>**

用途:图像分割,群体聚类,语言聚类,异常检测

聚类任务

>   在相同簇中的数据尽可能相似
>
>   在不同簇中的数据尽可能不同

**==聚类方法(必考)==**

>   基于数据间相似度的方法
>
>   基于密度估计的方法

## **1.K-means**

###### **1.K-means定义**

>   将k个聚类簇的中心作为簇的代表,希望所有数据点和聚类中心的距离总和最小
>
>   给定数据集$X \{x_1,x_2,\cdots,x_n\},x_n\in R^D $
>
>   聚类的类别为$z_n,n\in \{1,2,\cdots,N\}$
>
>   聚类中心为$\mu = \{\mu_1,\mu_2,\cdots,\mu_k\} $
>
>   存在目标函数

$$
J= \sum^{K}_{k=1}\sum^{N}_{n=1}I(z_n=k)||x_n-\mu_k||^2
$$

>   只有聚类类别相同的点才能继续求范数(距离)

###### **2.标准K-means流程**

->假如不知道聚类中心,可以随便从样本集x中选取k个直接假设为聚类中心,随机划分k个簇

迭代算法:

>->从簇中选取**一个**数据点$x_n $,计算移动后的距离
>$$
>\rho = \begin{cases}
>\frac{N_i}{N_i-1}||x_n-\mu_j||^2,&j=i(原始类别)
>\\
>\\
>\frac{N_j}{N_j+1}||x_n-\mu_j||^2,&j\not=i(其它的第一个类别)
>\\
>\\
>\cdots
>\\
>\\
>\frac{N_{j}}{N_j+1}||x_n-\mu_j||^2,&j\not=i(其它的第N个类别)
>\end{cases}
>$$
>->选择$\rho $最小的簇,将选取的数据点进行移动
>
>->重新计算聚类中心$\mu_1,\mu_2,\cdots,\mu_k $,以及误差平方项和J
>
>->直到总簇的误差平方项J保持不变

->输出:所有数据点对应的类别向量,聚类中心$\mu_1,\mu_2,\cdots ,\mu_k $,以及误差值

**每调整一个点,需要计算簇中心(K个),需要计算簇内的误差(K个),计算量大**

###### **2.批处理的K-means算法**

->假如不知道聚类中心,可以随便从样本集x中选取k个直接假设为聚类中心,随机划分k个簇

迭代算法:
>->把**每个**数据点$x_1,x_2,\cdots,x_N $,计算欧式距离$||x_n-\mu_k ||$
>
>>   根据求得的最小欧式距离,对**每个**样本点,直接划分到对应的簇
>
>->重新计算**每个**数据点的均值(样本中心)
>$$
>\mu_k = \frac{1}{N}\sum^{N}_{n=1}I(z_n=k)x_n
>$$
>->直到所有样本划分的类别不变

->输出:所有数据点对应的类别向量,聚类中心,(并没有计算误差值)

**<font color=red>并没有涉及误差函数,是一种贪心策略,要求距离最小即可,无法保证全局最小值</font>**

###### **3.聚类参数k的选取**

>   存在问题:给定数据不知道分多少个类别(k值未知)
>
>   1.经验法
>
>   >   误差会随着k的增加而下降,如果下降的幅度减小,那么可以确定一个k
>
>   2.线性代数法
>
>   >   通过行阶梯化简,看非0列(查找最大线性无关组个数)
>   >
>   >   实际上存在噪声,所以需要估计->具体的求特征值大小

最后一次作业:K-means算法(批处理k-means,标准k-means)数据集不限

## **2.模糊k-均值聚类**

不再直接使用二分来划分种类,而是引入了隶属度(或者称之为概率d),目标也是得到d->直接argmax判断

**目标函数引入了概率**
$$
argmin J = \sum^{K}_{k=1}\sum^{N}_{n=1}(d_{nk})^m||X_n-\mu_k||^2
\\ \\
s.t. \sum^{k}_{k=1}d_{nk}=1,n = 1,2,\cdots,n
$$

>   隶属度的初始化:随机初始或者直接通过距离

引入拉格朗日乘子法,转化为非约束问题
$$
argmin J = \sum^{K}_{k=1}\sum^{N}_{n=1}(d_{nk})^m||X_n-\mu_k||^2 + \sum^{N}_{n=1}a_n(\sum^{K}_{k1}d_{nk}-1)
$$
**求偏导等于0,得到两个表达式**
$$
\mu_k = \frac{\sum^{N}_{n=1}(d_{nk})^m x_n}{\sum^{N}_{n=1}(d_{nk})^m}\qquad d_{nk} = \frac{1}{\sum^{K}_{j=1}(\frac{||x_n-\mu_k||}{||x_n-\mu_j||})^{2l(m-1)}}
$$

>   所以对于这两个参数必须要先初始化一个
>
>   普通的迭代终点是距离不变,这里是隶属度不变,然后argmax直接判断

**==模糊在于隶属度初始化的不确定->模糊理论(效果其实没有NN好)==**

## **3.谱聚类(Important)**

**(推广系统)**

预处理:构建代表数据集的无向图并计算相似度矩阵->类似无向图,但是元素不是元素,而是相似度(2-范数)

谱表示:构建相应的laplace矩阵,并且计算其特征值和特征向量,其中一个或多个特征向量 构成了数据点在空间中的表示

>   这种空间表示就是特征值特征向量组成的新的空间,一种数据降维的方法,也是一种新的映射表示

聚类:使用聚类算法(K-means)对数据表示进行聚类

****

利用相似度矩阵构建带有权重的无向图G(V,E),计算Laplace矩阵

>   ==**主要思想:对无向图进行分割,对应不同的簇不可跨越**==
>
>   其中高斯相似度:（通过指数函数放大相似度差异）
>   $$
>   w_{ij} = w_P = e^{\frac{-||x_i-x_j||^2}{2\sigma^@}}
>   $$

laplace矩阵由相似度矩阵W和度矩阵D计算得到，度矩阵就是和其它顶点关联度的对角矩阵

>   $$
>   L  = D- W
>   $$
>
>   laplace矩阵性质：
>
>   >   1.二次型：
>   >   $$
>   >   a^T L a = \frac{1}{2}\sum^{N}_{i,j=1}w_{ij}(a_i-a_j)^2
>   >   $$
>   >   2.Laplace矩阵式对称半正定矩阵
>   >
>   >   3.最小特征值为0，对应的特征向量元素都为1
>   >
>   >   4.laplace矩阵具有N个非负特征值

**目标是图的最优割**

最优割的表示:$A,B\subset G,A\bigcap B=\emptyset $

并且切割后所有子图$A_1,A_2,\cdots,A_n $之间的权重和为（如果分好了则之间没有权重）

>   $$
>   W(A_1,A_2,\cdots,A_k) = \frac{1}{2}\sum^{K}_{k=1}W(A_k,G/A_K)
>   \\ \\
>   这里/不是除法，而是割
>   $$
>
>   >   即所有 子图的权重和其它剩余子图的权重的相似度 的和
>
>   优化方法：引入指示矩阵，矩阵的元素表示该位置的元素是否应该在当前类

**优化方法**

>   1.比率切割
>   $$
>   argmin \frac{1}{2}\sum^{K}_{k=1}\frac{W(A,G/A)}{|A_k|}
>   \\ \\
>   h_{i,k} = \begin{cases}
>   \frac{1}{\sqrt{|A_k|}}&if c_i\in A_k  \\ \\
>   0&otherwise
>   \end{cases}
>   $$
>
>   >   其中|A_i|表示节点个数
>
>   2.归一化切割
>   $$
>   argmin \frac{1}{2}\sum^{K}_{k=1}\frac{W(A,G/A)}{vol(A_k)}
>   \\ \\
>   h_{i,k} = \begin{cases}
>   \frac{1}{\sqrt{vol(A_k)}}&if c_i\in A_k  \\ \\
>   0&otherwise
>   \end{cases}
>   $$
>
>   >   其中vol(A_k）表示集合A种所有边权重和
>

**最优化问题重写**

>   **1.比率切割**
>   $$
>   \frac{W(A_k,G/A_k)}{|A_k|} = \frac{1}{2}\sum^{N}_{i=1}\sum^{N}_{j=1}w_{{ij}}(h_{ik}-h_{jk})^2 = h^T_k Lh_k
>   \\ \\
>   \therefore 
>   \begin{cases}
>   argmin \frac{1}{2}\sum^{K}_{k=1}\frac{W(A,G/A)}{|A_k|}
>   \\ \\
>   h_{i,k} = \begin{cases}
>   \frac{1}{\sqrt{|A_k|}}&if c_i\in A_k  \\ \\
>   0&otherwise
>   \end{cases}
>   \end{cases}
>   \Rightarrow 
>   \begin{cases}
>   argmin \ Trace(H^T LH)
>   \\ \\
>   s.t. H^TH =1\end{cases}
>   $$
>   将H约束

>   然后拉格朗日乘子法





所谓的谱：特征值和特征向量，谱半径：最大的特征向量->谱分析

谱分析和半监督的流式构型的主要任务不一样

